{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise: Business cycle correlations\n",
    "\n",
    "For this exercise, you'll be using macroeconomic data from the folder `../data/FRED`.\n",
    "\n",
    "1.  There are seven decade-specific files named `FRED_monthly_19X0.csv` where `X` identifies the decade (`X` takes on the values 5, 6, 7, 8, 9, 0, 1). Write a loop that reads in all seven files as DataFrames and store them in a list.\n",
    "\n",
    "    *Hint:* Recall from the lecture that you should use <TT>pd.read_csv(..., parse_dates=['DATE'])</TT> to automatically parse strings stored in the <TT>DATE</TT> column as dates.\n",
    "2.  Use [`pd.concat()`](https://pandas.pydata.org/docs/reference/api/pandas.concat.html) to concate these data sets into a single `DataFrame` and set the `DATE` column as the index.\n",
    "3.  You realize that your data does not include GDP since this variable is only reported at quarterly frequency.\n",
    "    Load the GDP data from the file `GDP.csv` and merge it with your monthly data using an _inner join_.\n",
    "4.  You want to compute how (percent) changes of the variables in your data correlate with percent changes in GDP.\n",
    "\n",
    "    1. Create a _new_ `DataFrame` which contains the percent changes in CPI and GDP (using \n",
    "    [`pct_change()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pct_change.html), \n",
    "    see also the last exercise in workshop 3),\n",
    "    and the absolute changes for the remaining variables (using \n",
    "    [`diff()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.diff.html)).\n",
    "    2.  Compute the correlation of the percent changes in GDP with the (percent) changes of all other variables (using [`corr()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corr.html)). What does the sign and magnitude of the correlation coefficient tell you?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "DATA_PATH = '/Users/olavgramstadberstad/Desktop/repos/TECH2-H24/data/FRED'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[          DATE   CPI  UNRATE  FEDFUNDS  REALRATE  LFPART\n",
       " 0   1950-01-01  23.5     6.5       NaN       NaN    58.9\n",
       " 1   1950-02-01  23.6     6.4       NaN       NaN    58.9\n",
       " 2   1950-03-01  23.6     6.3       NaN       NaN    58.8\n",
       " 3   1950-04-01  23.6     5.8       NaN       NaN    59.2\n",
       " 4   1950-05-01  23.8     5.5       NaN       NaN    59.1\n",
       " ..         ...   ...     ...       ...       ...     ...\n",
       " 115 1959-08-01  29.2     5.2       3.5       NaN    59.2\n",
       " 116 1959-09-01  29.2     5.5       3.8       NaN    59.3\n",
       " 117 1959-10-01  29.4     5.7       4.0       NaN    59.4\n",
       " 118 1959-11-01  29.4     5.8       4.0       NaN    59.1\n",
       " 119 1959-12-01  29.4     5.3       4.0       NaN    59.5\n",
       " \n",
       " [120 rows x 6 columns],\n",
       "           DATE   CPI  UNRATE  FEDFUNDS  REALRATE  LFPART\n",
       " 0   1960-01-01  29.4     5.2       4.0       NaN    59.1\n",
       " 1   1960-02-01  29.4     4.8       4.0       NaN    59.1\n",
       " 2   1960-03-01  29.4     5.4       3.8       NaN    58.5\n",
       " 3   1960-04-01  29.5     5.2       3.9       NaN    59.5\n",
       " 4   1960-05-01  29.6     5.1       3.8       NaN    59.5\n",
       " ..         ...   ...     ...       ...       ...     ...\n",
       " 115 1969-08-01  36.9     3.5       9.2       NaN    60.3\n",
       " 116 1969-09-01  37.1     3.7       9.2       NaN    60.3\n",
       " 117 1969-10-01  37.3     3.7       9.0       NaN    60.4\n",
       " 118 1969-11-01  37.5     3.5       8.8       NaN    60.2\n",
       " 119 1969-12-01  37.7     3.5       9.0       NaN    60.2\n",
       " \n",
       " [120 rows x 6 columns],\n",
       "           DATE   CPI  UNRATE  FEDFUNDS  REALRATE  LFPART\n",
       " 0   1970-01-01  37.9     3.9       9.0       NaN    60.4\n",
       " 1   1970-02-01  38.1     4.2       9.0       NaN    60.4\n",
       " 2   1970-03-01  38.3     4.4       7.8       NaN    60.6\n",
       " 3   1970-04-01  38.5     4.6       8.1       NaN    60.6\n",
       " 4   1970-05-01  38.6     4.8       8.0       NaN    60.3\n",
       " ..         ...   ...     ...       ...       ...     ...\n",
       " 115 1979-08-01  73.7     6.0      10.9       NaN    63.6\n",
       " 116 1979-09-01  74.4     5.9      11.4       NaN    63.8\n",
       " 117 1979-10-01  75.2     6.0      13.8       NaN    63.7\n",
       " 118 1979-11-01  76.0     5.9      13.2       NaN    63.7\n",
       " 119 1979-12-01  76.9     6.0      13.8       NaN    63.9\n",
       " \n",
       " [120 rows x 6 columns],\n",
       "           DATE    CPI  UNRATE  FEDFUNDS  REALRATE  LFPART\n",
       " 0   1980-01-01   78.0     6.3      13.8       NaN    64.0\n",
       " 1   1980-02-01   79.0     6.3      14.1       NaN    64.0\n",
       " 2   1980-03-01   80.1     6.3      17.2       NaN    63.7\n",
       " 3   1980-04-01   80.9     6.9      17.6       NaN    63.8\n",
       " 4   1980-05-01   81.7     7.5      11.0       NaN    63.9\n",
       " ..         ...    ...     ...       ...       ...     ...\n",
       " 115 1989-08-01  124.5     5.2       9.0       3.7    66.5\n",
       " 116 1989-09-01  124.8     5.3       9.0       4.0    66.4\n",
       " 117 1989-10-01  125.4     5.3       8.8       3.9    66.5\n",
       " 118 1989-11-01  125.9     5.4       8.6       3.9    66.6\n",
       " 119 1989-12-01  126.3     5.4       8.4       3.9    66.5\n",
       " \n",
       " [120 rows x 6 columns],\n",
       "           DATE    CPI  UNRATE  FEDFUNDS  REALRATE  LFPART\n",
       " 0   1990-01-01  127.5     5.4       8.2       3.8    66.8\n",
       " 1   1990-02-01  128.0     5.3       8.2       3.4    66.7\n",
       " 2   1990-03-01  128.6     5.2       8.3       4.4    66.7\n",
       " 3   1990-04-01  128.9     5.4       8.3       4.5    66.6\n",
       " 4   1990-05-01  129.1     5.4       8.2       4.3    66.6\n",
       " ..         ...    ...     ...       ...       ...     ...\n",
       " 115 1999-08-01  167.1     4.2       5.1       2.6    67.0\n",
       " 116 1999-09-01  167.8     4.2       5.2       2.7    67.0\n",
       " 117 1999-10-01  168.1     4.1       5.2       2.3    67.0\n",
       " 118 1999-11-01  168.4     4.1       5.4       2.2    67.1\n",
       " 119 1999-12-01  168.8     4.0       5.3       1.8    67.1\n",
       " \n",
       " [120 rows x 6 columns],\n",
       "           DATE    CPI  UNRATE  FEDFUNDS  REALRATE  LFPART\n",
       " 0   2000-01-01  169.3     4.0       5.4       2.7    67.3\n",
       " 1   2000-02-01  170.0     4.1       5.7       2.6    67.3\n",
       " 2   2000-03-01  171.0     4.0       5.8       2.7    67.3\n",
       " 3   2000-04-01  170.9     3.8       6.0       2.9    67.3\n",
       " 4   2000-05-01  171.2     4.0       6.3       2.8    67.1\n",
       " ..         ...    ...     ...       ...       ...     ...\n",
       " 115 2009-08-01  215.4     9.6       0.2      -1.0    65.4\n",
       " 116 2009-09-01  215.9     9.8       0.2      -1.9    65.1\n",
       " 117 2009-10-01  216.5    10.0       0.1      -0.8    65.0\n",
       " 118 2009-11-01  217.2     9.9       0.1      -1.0    65.0\n",
       " 119 2009-12-01  217.3     9.9       0.1      -1.2    64.6\n",
       " \n",
       " [120 rows x 6 columns],\n",
       "           DATE    CPI  UNRATE  FEDFUNDS  REALRATE  LFPART\n",
       " 0   2010-01-01  217.5     9.8       0.1      -0.8    64.8\n",
       " 1   2010-02-01  217.3     9.8       0.1      -1.1    64.9\n",
       " 2   2010-03-01  217.4     9.9       0.2      -1.6    64.9\n",
       " 3   2010-04-01  217.4     9.9       0.2      -0.4    65.2\n",
       " 4   2010-05-01  217.3     9.6       0.2      -0.5    64.9\n",
       " ..         ...    ...     ...       ...       ...     ...\n",
       " 115 2019-08-01  256.0     3.6       2.1       0.6    63.1\n",
       " 116 2019-09-01  256.4     3.5       2.0       0.3    63.2\n",
       " 117 2019-10-01  257.2     3.6       1.8      -0.0    63.3\n",
       " 118 2019-11-01  257.9     3.6       1.6      -0.2    63.3\n",
       " 119 2019-12-01  258.6     3.6       1.6      -0.3    63.3\n",
       " \n",
       " [120 rows x 6 columns]]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1\n",
    "DataFrames = []\n",
    "\n",
    "for i in range(5,10):\n",
    "    DataFrames.append(pd.read_csv(f'{DATA_PATH}/FRED_monthly_19{i}0.csv', parse_dates=['DATE']))\n",
    "\n",
    "for i in range(0,2):\n",
    "    DataFrames.append(pd.read_csv(f'{DATA_PATH}/FRED_monthly_20{i}0.csv', parse_dates=['DATE']))\n",
    "\n",
    "DataFrames "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CPI</th>\n",
       "      <th>UNRATE</th>\n",
       "      <th>FEDFUNDS</th>\n",
       "      <th>REALRATE</th>\n",
       "      <th>LFPART</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23.5</td>\n",
       "      <td>6.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.6</td>\n",
       "      <td>6.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23.6</td>\n",
       "      <td>6.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.6</td>\n",
       "      <td>5.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23.8</td>\n",
       "      <td>5.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>256.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>63.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>256.4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>63.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>257.2</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>63.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>257.9</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.6</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>63.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839</th>\n",
       "      <td>258.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.6</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>63.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>840 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CPI  UNRATE  FEDFUNDS  REALRATE  LFPART\n",
       "0     23.5     6.5       NaN       NaN    58.9\n",
       "1     23.6     6.4       NaN       NaN    58.9\n",
       "2     23.6     6.3       NaN       NaN    58.8\n",
       "3     23.6     5.8       NaN       NaN    59.2\n",
       "4     23.8     5.5       NaN       NaN    59.1\n",
       "..     ...     ...       ...       ...     ...\n",
       "835  256.0     3.6       2.1       0.6    63.1\n",
       "836  256.4     3.5       2.0       0.3    63.2\n",
       "837  257.2     3.6       1.8      -0.0    63.3\n",
       "838  257.9     3.6       1.6      -0.2    63.3\n",
       "839  258.6     3.6       1.6      -0.3    63.3\n",
       "\n",
       "[840 rows x 5 columns]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2\n",
    "DataFrames = pd.concat(DataFrames)\n",
    "DataFrames.set_index('DATE').reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>CPI</th>\n",
       "      <th>UNRATE</th>\n",
       "      <th>FEDFUNDS</th>\n",
       "      <th>REALRATE</th>\n",
       "      <th>LFPART</th>\n",
       "      <th>GDP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1950-01-01</td>\n",
       "      <td>23.5</td>\n",
       "      <td>6.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58.9</td>\n",
       "      <td>2346.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1950-04-01</td>\n",
       "      <td>23.6</td>\n",
       "      <td>5.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.2</td>\n",
       "      <td>2417.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1950-07-01</td>\n",
       "      <td>24.1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.1</td>\n",
       "      <td>2511.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1950-10-01</td>\n",
       "      <td>24.5</td>\n",
       "      <td>4.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.4</td>\n",
       "      <td>2559.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1951-01-01</td>\n",
       "      <td>25.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.1</td>\n",
       "      <td>2594.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>2018-10-01</td>\n",
       "      <td>252.8</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2.2</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>62.9</td>\n",
       "      <td>20304.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>252.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>63.1</td>\n",
       "      <td>20431.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>255.2</td>\n",
       "      <td>3.7</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.1</td>\n",
       "      <td>62.8</td>\n",
       "      <td>20602.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>255.8</td>\n",
       "      <td>3.7</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.1</td>\n",
       "      <td>63.1</td>\n",
       "      <td>20843.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>257.2</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>63.3</td>\n",
       "      <td>20985.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>280 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          DATE    CPI  UNRATE  FEDFUNDS  REALRATE  LFPART      GDP\n",
       "0   1950-01-01   23.5     6.5       NaN       NaN    58.9   2346.1\n",
       "1   1950-04-01   23.6     5.8       NaN       NaN    59.2   2417.7\n",
       "2   1950-07-01   24.1     5.0       NaN       NaN    59.1   2511.1\n",
       "3   1950-10-01   24.5     4.2       NaN       NaN    59.4   2559.2\n",
       "4   1951-01-01   25.4     3.7       NaN       NaN    59.1   2594.0\n",
       "..         ...    ...     ...       ...       ...     ...      ...\n",
       "275 2018-10-01  252.8     3.8       2.2      -0.2    62.9  20304.9\n",
       "276 2019-01-01  252.6     4.0       2.4       0.6    63.1  20431.6\n",
       "277 2019-04-01  255.2     3.7       2.4       3.1    62.8  20602.3\n",
       "278 2019-07-01  255.8     3.7       2.4       1.1    63.1  20843.3\n",
       "279 2019-10-01  257.2     3.6       1.8      -0.0    63.3  20985.4\n",
       "\n",
       "[280 rows x 7 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdp = pd.read_csv(f'{DATA_PATH}/GDP.csv', parse_dates=['DATE'])\n",
    "DataFrames1 = pd.merge(DataFrames, gdp, on='DATE', how='inner')\n",
    "DataFrames1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CPI</th>\n",
       "      <th>GDP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1950-01-01</th>\n",
       "      <td>23.5</td>\n",
       "      <td>2346.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950-04-01</th>\n",
       "      <td>23.6</td>\n",
       "      <td>2417.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950-07-01</th>\n",
       "      <td>24.1</td>\n",
       "      <td>2511.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950-10-01</th>\n",
       "      <td>24.5</td>\n",
       "      <td>2559.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1951-01-01</th>\n",
       "      <td>25.4</td>\n",
       "      <td>2594.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-01</th>\n",
       "      <td>252.8</td>\n",
       "      <td>20304.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01</th>\n",
       "      <td>252.6</td>\n",
       "      <td>20431.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-01</th>\n",
       "      <td>255.2</td>\n",
       "      <td>20602.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-01</th>\n",
       "      <td>255.8</td>\n",
       "      <td>20843.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-01</th>\n",
       "      <td>257.2</td>\n",
       "      <td>20985.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>280 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              CPI      GDP\n",
       "DATE                      \n",
       "1950-01-01   23.5   2346.1\n",
       "1950-04-01   23.6   2417.7\n",
       "1950-07-01   24.1   2511.1\n",
       "1950-10-01   24.5   2559.2\n",
       "1951-01-01   25.4   2594.0\n",
       "...           ...      ...\n",
       "2018-10-01  252.8  20304.9\n",
       "2019-01-01  252.6  20431.6\n",
       "2019-04-01  255.2  20602.3\n",
       "2019-07-01  255.8  20843.3\n",
       "2019-10-01  257.2  20985.4\n",
       "\n",
       "[280 rows x 2 columns]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = DataFrames1[['DATE', 'CPI', 'GDP']].set_index('DATE')\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CPI</th>\n",
       "      <th>GDP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1950-01-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950-04-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950-07-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950-10-01</th>\n",
       "      <td>4.255319</td>\n",
       "      <td>9.083159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1951-01-01</th>\n",
       "      <td>7.627119</td>\n",
       "      <td>7.292054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-01</th>\n",
       "      <td>1.566894</td>\n",
       "      <td>1.301131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01</th>\n",
       "      <td>0.959233</td>\n",
       "      <td>1.395003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-01</th>\n",
       "      <td>1.592357</td>\n",
       "      <td>1.608290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-01</th>\n",
       "      <td>1.186709</td>\n",
       "      <td>2.651577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-01</th>\n",
       "      <td>1.821061</td>\n",
       "      <td>2.710507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>280 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 CPI       GDP\n",
       "DATE                          \n",
       "1950-01-01       NaN       NaN\n",
       "1950-04-01       NaN       NaN\n",
       "1950-07-01       NaN       NaN\n",
       "1950-10-01  4.255319  9.083159\n",
       "1951-01-01  7.627119  7.292054\n",
       "...              ...       ...\n",
       "2018-10-01  1.566894  1.301131\n",
       "2019-01-01  0.959233  1.395003\n",
       "2019-04-01  1.592357  1.608290\n",
       "2019-07-01  1.186709  2.651577\n",
       "2019-10-01  1.821061  2.710507\n",
       "\n",
       "[280 rows x 2 columns]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df1.pct_change(periods=3)*100\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CPI</th>\n",
       "      <th>GDP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1950-01-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950-04-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950-07-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950-10-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1951-01-01</th>\n",
       "      <td>3.371799</td>\n",
       "      <td>-1.791105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-01</th>\n",
       "      <td>-0.298475</td>\n",
       "      <td>-0.679515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01</th>\n",
       "      <td>-0.607662</td>\n",
       "      <td>0.093872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-01</th>\n",
       "      <td>0.633124</td>\n",
       "      <td>0.213287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-01</th>\n",
       "      <td>-0.405648</td>\n",
       "      <td>1.043287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-01</th>\n",
       "      <td>0.634352</td>\n",
       "      <td>0.058931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>280 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 CPI       GDP\n",
       "DATE                          \n",
       "1950-01-01       NaN       NaN\n",
       "1950-04-01       NaN       NaN\n",
       "1950-07-01       NaN       NaN\n",
       "1950-10-01       NaN       NaN\n",
       "1951-01-01  3.371799 -1.791105\n",
       "...              ...       ...\n",
       "2018-10-01 -0.298475 -0.679515\n",
       "2019-01-01 -0.607662  0.093872\n",
       "2019-04-01  0.633124  0.213287\n",
       "2019-07-01 -0.405648  1.043287\n",
       "2019-10-01  0.634352  0.058931\n",
       "\n",
       "[280 rows x 2 columns]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df1.diff()\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot perform __truediv__ with this index type: DatetimeArray",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[149], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m DataFrames1\u001b[38;5;241m.\u001b[39mpct_change(periods\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/generic.py:12161\u001b[0m, in \u001b[0;36mNDFrame.pct_change\u001b[0;34m(self, periods, fill_method, limit, freq, **kwargs)\u001b[0m\n\u001b[1;32m  12159\u001b[0m shifted \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mshift(periods\u001b[38;5;241m=\u001b[39mperiods, freq\u001b[38;5;241m=\u001b[39mfreq, axis\u001b[38;5;241m=\u001b[39maxis, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m  12160\u001b[0m \u001b[38;5;66;03m# Unsupported left operand type for / (\"Self\")\u001b[39;00m\n\u001b[0;32m> 12161\u001b[0m rs \u001b[38;5;241m=\u001b[39m data \u001b[38;5;241m/\u001b[39m shifted \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# type: ignore[operator]\u001b[39;00m\n\u001b[1;32m  12162\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m freq \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m  12163\u001b[0m     \u001b[38;5;66;03m# Shift method is implemented differently when freq is not None\u001b[39;00m\n\u001b[1;32m  12164\u001b[0m     \u001b[38;5;66;03m# We want to restore the original index\u001b[39;00m\n\u001b[1;32m  12165\u001b[0m     rs \u001b[38;5;241m=\u001b[39m rs\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;241m~\u001b[39mrs\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mduplicated()]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/ops/common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m     74\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m method(\u001b[38;5;28mself\u001b[39m, other)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/arraylike.py:210\u001b[0m, in \u001b[0;36mOpsMixin.__truediv__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__truediv__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__truediv__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m--> 210\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_arith_method(other, operator\u001b[38;5;241m.\u001b[39mtruediv)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/frame.py:7913\u001b[0m, in \u001b[0;36mDataFrame._arith_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   7910\u001b[0m \u001b[38;5;28mself\u001b[39m, other \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_align_for_op(other, axis, flex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, level\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m   7912\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 7913\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch_frame_op(other, op, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[1;32m   7914\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(new_data)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/frame.py:7956\u001b[0m, in \u001b[0;36mDataFrame._dispatch_frame_op\u001b[0;34m(self, right, func, axis)\u001b[0m\n\u001b[1;32m   7950\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mequals(right\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[1;32m   7951\u001b[0m     \u001b[38;5;66;03m# TODO: The previous assertion `assert right._indexed_same(self)`\u001b[39;00m\n\u001b[1;32m   7952\u001b[0m     \u001b[38;5;66;03m#  fails in cases with empty columns reached via\u001b[39;00m\n\u001b[1;32m   7953\u001b[0m     \u001b[38;5;66;03m#  _frame_arith_method_with_reindex\u001b[39;00m\n\u001b[1;32m   7954\u001b[0m \n\u001b[1;32m   7955\u001b[0m     \u001b[38;5;66;03m# TODO operate_blockwise expects a manager of the same type\u001b[39;00m\n\u001b[0;32m-> 7956\u001b[0m     bm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39moperate_blockwise(\n\u001b[1;32m   7957\u001b[0m         \u001b[38;5;66;03m# error: Argument 1 to \"operate_blockwise\" of \"ArrayManager\" has\u001b[39;00m\n\u001b[1;32m   7958\u001b[0m         \u001b[38;5;66;03m# incompatible type \"Union[ArrayManager, BlockManager]\"; expected\u001b[39;00m\n\u001b[1;32m   7959\u001b[0m         \u001b[38;5;66;03m# \"ArrayManager\"\u001b[39;00m\n\u001b[1;32m   7960\u001b[0m         \u001b[38;5;66;03m# error: Argument 1 to \"operate_blockwise\" of \"BlockManager\" has\u001b[39;00m\n\u001b[1;32m   7961\u001b[0m         \u001b[38;5;66;03m# incompatible type \"Union[ArrayManager, BlockManager]\"; expected\u001b[39;00m\n\u001b[1;32m   7962\u001b[0m         \u001b[38;5;66;03m# \"BlockManager\"\u001b[39;00m\n\u001b[1;32m   7963\u001b[0m         right\u001b[38;5;241m.\u001b[39m_mgr,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m   7964\u001b[0m         array_op,\n\u001b[1;32m   7965\u001b[0m     )\n\u001b[1;32m   7966\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(bm, axes\u001b[38;5;241m=\u001b[39mbm\u001b[38;5;241m.\u001b[39maxes)\n\u001b[1;32m   7968\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(right, Series) \u001b[38;5;129;01mand\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   7969\u001b[0m     \u001b[38;5;66;03m# axis=1 means we want to operate row-by-row\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/internals/managers.py:1511\u001b[0m, in \u001b[0;36mBlockManager.operate_blockwise\u001b[0;34m(self, other, array_op)\u001b[0m\n\u001b[1;32m   1507\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moperate_blockwise\u001b[39m(\u001b[38;5;28mself\u001b[39m, other: BlockManager, array_op) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BlockManager:\n\u001b[1;32m   1508\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1509\u001b[0m \u001b[38;5;124;03m    Apply array_op blockwise with another (aligned) BlockManager.\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m operate_blockwise(\u001b[38;5;28mself\u001b[39m, other, array_op)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/internals/ops.py:65\u001b[0m, in \u001b[0;36moperate_blockwise\u001b[0;34m(left, right, array_op)\u001b[0m\n\u001b[1;32m     63\u001b[0m res_blks: \u001b[38;5;28mlist\u001b[39m[Block] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m lvals, rvals, locs, left_ea, right_ea, rblk \u001b[38;5;129;01min\u001b[39;00m _iter_block_pairs(left, right):\n\u001b[0;32m---> 65\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m array_op(lvals, rvals)\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m     67\u001b[0m         left_ea\n\u001b[1;32m     68\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m right_ea\n\u001b[1;32m     69\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(res_values, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreshape\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     70\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_1d_only_ea_dtype(res_values\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m     71\u001b[0m     ):\n\u001b[1;32m     72\u001b[0m         res_values \u001b[38;5;241m=\u001b[39m res_values\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/ops/array_ops.py:273\u001b[0m, in \u001b[0;36marithmetic_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;66;03m# NB: We assume that extract_array and ensure_wrapped_if_datetimelike\u001b[39;00m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;66;03m#  have already been called on `left` and `right`,\u001b[39;00m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;66;03m#  and `maybe_prepare_scalar_for_op` has already been called on `right`\u001b[39;00m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# We need to special-case datetime64/timedelta64 dtypes (e.g. because numpy\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# casts integer dtypes to timedelta64 when operating with timedelta64 - GH#22390)\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    267\u001b[0m     should_extension_dispatch(left, right)\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(right, (Timedelta, BaseOffset, Timestamp))\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;66;03m# Timedelta/Timestamp and other custom scalars are included in the check\u001b[39;00m\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;66;03m# because numexpr will fail on it, see GH#31457\u001b[39;00m\n\u001b[0;32m--> 273\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m op(left, right)\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;66;03m# TODO we should handle EAs consistently and move this check before the if/else\u001b[39;00m\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;66;03m# (https://github.com/pandas-dev/pandas/issues/41165)\u001b[39;00m\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;66;03m# error: Argument 2 to \"_bool_arith_check\" has incompatible type\u001b[39;00m\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;66;03m# \"Union[ExtensionArray, ndarray[Any, Any]]\"; expected \"ndarray[Any, Any]\"\u001b[39;00m\n\u001b[1;32m    279\u001b[0m     _bool_arith_check(op, left, right)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/ops/common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m     74\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m method(\u001b[38;5;28mself\u001b[39m, other)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/ops/invalid.py:59\u001b[0m, in \u001b[0;36mmake_invalid_op.<locals>.invalid_op\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvalid_op\u001b[39m(\u001b[38;5;28mself\u001b[39m, other\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     58\u001b[0m     typ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot perform \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with this index type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtyp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot perform __truediv__ with this index type: DatetimeArray"
     ]
    }
   ],
   "source": [
    "DataFrames1.pct_change(periods=3)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Exercise: Loading many data files\n",
    "\n",
    "In the previous exercise, you loaded the individual files by specifing an explicit list of file names. This can become tedious or infeasible if your data is spread across many files with varying file name patterns. Python offers the possibility to iterate over all files in a directory (for example, using [`os.listdir()`](https://docs.python.org/3/library/os.html#os.listdir)),\n",
    "or to iterate over files that match a pattern, for example using [`glob.glob()`](https://docs.python.org/3/library/glob.html).\n",
    "\n",
    "Repeat parts (1) and (2) from the previous exercise, but now iterate over the input files using \n",
    "[`glob.glob()`](https://docs.python.org/3/library/glob.html). You'll need to use a wildcard `*` and make sure to match only the relevant files in `../data/FRED`, i.e., those that start with `FRED_monthly`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CPI</th>\n",
       "      <th>UNRATE</th>\n",
       "      <th>FEDFUNDS</th>\n",
       "      <th>REALRATE</th>\n",
       "      <th>LFPART</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1950-01-01</th>\n",
       "      <td>23.5</td>\n",
       "      <td>6.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950-02-01</th>\n",
       "      <td>23.6</td>\n",
       "      <td>6.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950-03-01</th>\n",
       "      <td>23.6</td>\n",
       "      <td>6.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950-04-01</th>\n",
       "      <td>23.6</td>\n",
       "      <td>5.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950-05-01</th>\n",
       "      <td>23.8</td>\n",
       "      <td>5.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1969-08-01</th>\n",
       "      <td>36.9</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1969-09-01</th>\n",
       "      <td>37.1</td>\n",
       "      <td>3.7</td>\n",
       "      <td>9.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1969-10-01</th>\n",
       "      <td>37.3</td>\n",
       "      <td>3.7</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1969-11-01</th>\n",
       "      <td>37.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1969-12-01</th>\n",
       "      <td>37.7</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>840 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             CPI  UNRATE  FEDFUNDS  REALRATE  LFPART\n",
       "DATE                                                \n",
       "1950-01-01  23.5     6.5       NaN       NaN    58.9\n",
       "1950-02-01  23.6     6.4       NaN       NaN    58.9\n",
       "1950-03-01  23.6     6.3       NaN       NaN    58.8\n",
       "1950-04-01  23.6     5.8       NaN       NaN    59.2\n",
       "1950-05-01  23.8     5.5       NaN       NaN    59.1\n",
       "...          ...     ...       ...       ...     ...\n",
       "1969-08-01  36.9     3.5       9.2       NaN    60.3\n",
       "1969-09-01  37.1     3.7       9.2       NaN    60.3\n",
       "1969-10-01  37.3     3.7       9.0       NaN    60.4\n",
       "1969-11-01  37.5     3.5       8.8       NaN    60.2\n",
       "1969-12-01  37.7     3.5       9.0       NaN    60.2\n",
       "\n",
       "[840 rows x 5 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "data_list = []\n",
    "DATA_PATH2 = glob.glob('/Users/olavgramstadberstad/Desktop/repos/TECH2-H24/data/FRED/FRED_monthly_*.csv')\n",
    "for file in DATA_PATH2:\n",
    "    data_list.append(pd.read_csv(file, parse_dates=['DATE']))\n",
    "\n",
    "df_1 = pd.concat(data_list).set_index('DATE')\n",
    "df_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Exercise: Decade averages of macro time series\n",
    "\n",
    "\n",
    "For this exercise, you'll be using macroeconomic data from the folder `../data/FRED`.\n",
    "\n",
    "1.  There are five files containing monthly observations on annual inflation (INFLATION), the Fed Funds rate (FEDFUNDS), the labor force participation rate (LFPART), the 1-year real interest rate (REALRATE) and the unemployment rate (UNRATE).\n",
    "    Write a loop to import these and merge them on `DATE` into a single `DataFrame` using _outer joins_ (recall that [`merge()`](https://pandas.pydata.org/docs/reference/api/pandas.merge.html) \n",
    "    and [`join()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.join.html) operate on only two DataFrames at a time). \n",
    "\n",
    "    *Hint:* Recall from the lecture that you should use <TT>pd.read_csv(..., parse_dates=['DATE'])</TT> to automatically parse strings stored in the <TT>DATE</TT> column as dates.\n",
    "\n",
    "2.  Your friend is a pandas guru and tells you that you don't need to iteratively merge many files but can instead directly use [`pd.concat()`](https://pandas.pydata.org/docs/reference/api/pandas.concat.html) for merging many DataFrames in a single step.\n",
    "    Repeat the previous part using `pd.concat()` instead, and verify that you get the same result (you can do this using [`compare()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.compare.html)).\n",
    "3.  You want to compute the average value of each variable by decade, but you want to include only decades without _any_ missing values for _all_ variables.\n",
    "    1.  Create a variable `Decade` which stores the decade (1940, 1950, ...) for each observation.\n",
    "\n",
    "        *Hint:* You should have set the `DATE` as the `DataFrame` index. Then you can access the calendar year using the attribute `df.index.year` which can be used to compute the decade.\n",
    "    2.  Write a function `num_missing(x)` which takes as argument `x` a `Series` and returns the number of missing values in this `Series`.\n",
    "    3.  Compute the number of missing values by decade for each variable using a [`groupby()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html) operation and the function `num_missing` you wrote.\n",
    "    4.  Aggregate this data across all variables to create an indicator for each decade whether there are any missing values. This can be done in many ways but will require aggregation across columns, e.g., with `sum(..., axis=1)`.\n",
    "    5.  Merge this decade-level indicator data back into the original `DataFrame` (_many-to-one_ merge). \n",
    "4.  Using this indicator, drop all observations which are in a decade with missing values.\n",
    "5.  Compute the decade average for each variable.\n",
    "\n",
    "**Challenge**\n",
    "\n",
    "-   Your pandas guru friend claims that all the steps in 3.2 to 3.5 can be done with a single one-liner using [`transform()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.transform.html). Can you come up with a solution?\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[          DATE  INFLATION\n",
       " 0   1948-01-01       10.2\n",
       " 1   1948-02-01        9.7\n",
       " 2   1948-03-01        6.8\n",
       " 3   1948-04-01        8.2\n",
       " 4   1948-05-01        9.1\n",
       " ..         ...        ...\n",
       " 915 2024-04-01        3.4\n",
       " 916 2024-05-01        3.2\n",
       " 917 2024-06-01        3.0\n",
       " 918 2024-07-01        2.9\n",
       " 919 2024-08-01        2.6\n",
       " \n",
       " [920 rows x 2 columns],\n",
       "           DATE  FEDFUNDS\n",
       " 0   1954-07-01       0.8\n",
       " 1   1954-08-01       1.2\n",
       " 2   1954-09-01       1.1\n",
       " 3   1954-10-01       0.8\n",
       " 4   1954-11-01       0.8\n",
       " ..         ...       ...\n",
       " 838 2024-05-01       5.3\n",
       " 839 2024-06-01       5.3\n",
       " 840 2024-07-01       5.3\n",
       " 841 2024-08-01       5.3\n",
       " 842 2024-09-01       5.1\n",
       " \n",
       " [843 rows x 2 columns],\n",
       "           DATE  LFPART\n",
       " 0   1948-01-01    58.6\n",
       " 1   1948-02-01    58.9\n",
       " 2   1948-03-01    58.5\n",
       " 3   1948-04-01    59.0\n",
       " 4   1948-05-01    58.3\n",
       " ..         ...     ...\n",
       " 916 2024-05-01    62.5\n",
       " 917 2024-06-01    62.6\n",
       " 918 2024-07-01    62.7\n",
       " 919 2024-08-01    62.7\n",
       " 920 2024-09-01    62.7\n",
       " \n",
       " [921 rows x 2 columns],\n",
       "           DATE  REALRATE\n",
       " 0   1982-01-01       4.3\n",
       " 1   1982-02-01       6.7\n",
       " 2   1982-03-01       7.7\n",
       " 3   1982-04-01       8.2\n",
       " 4   1982-05-01       8.3\n",
       " ..         ...       ...\n",
       " 509 2024-06-01       2.3\n",
       " 510 2024-07-01       2.5\n",
       " 511 2024-08-01       2.5\n",
       " 512 2024-09-01       2.4\n",
       " 513 2024-10-01       2.1\n",
       " \n",
       " [514 rows x 2 columns],\n",
       "           DATE  UNRATE\n",
       " 0   1948-01-01     3.4\n",
       " 1   1948-02-01     3.8\n",
       " 2   1948-03-01     4.0\n",
       " 3   1948-04-01     3.9\n",
       " 4   1948-05-01     3.5\n",
       " ..         ...     ...\n",
       " 916 2024-05-01     4.0\n",
       " 917 2024-06-01     4.1\n",
       " 918 2024-07-01     4.3\n",
       " 919 2024-08-01     4.2\n",
       " 920 2024-09-01     4.1\n",
       " \n",
       " [921 rows x 2 columns]]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataFrames2 = []\n",
    "\n",
    "for file in ['INFLATION', 'FEDFUNDS', 'LFPART', 'REALRATE', 'UNRATE']:\n",
    "    DataFrames2.append(pd.read_csv(f'{DATA_PATH}/{file}.csv', parse_dates=['DATE']))\n",
    "    \n",
    "\n",
    "DataFrames2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Exercise: Mering the Titanic data\n",
    "\n",
    "In this exercise, you'll be working with the the original Titanic data set in `titanic.csv` and additional (partly fictitious) information on passengers stored in `titanic-additional.csv`, both located in the `data/` folder.\n",
    "\n",
    "The goal of the exercise is to calculate the survival rates by country of residence (for this exercise we restrict ourselves to the UK, so these will be England, Scotland, etc.).\n",
    "\n",
    "1.  Load the `titanic.csv` and `titanic-additional.csv` into two DataFrames.\n",
    "\n",
    "    Inspect the columns contained in both data sets. As you can see, the original data contains the full name including the title\n",
    "    and potentially maiden name (for married women) in a single column.\n",
    "    The additional data contains this information in separate columns.\n",
    "    You want to merge these data sets, but you first need to create common keys in both DataFrames.\n",
    "\n",
    "2.  Since the only common information is the name, you'll need to extract the individual name components from the original DataFrame\n",
    "    and use these as merge keys.\n",
    "\n",
    "    Focusing only on men (who have names that are much easier to parse), split the `Name` column into the tokens \n",
    "    `Title`, `FirstName` and `LastName`, just like the columns in the second DataFrame.\n",
    "\n",
    "    *Hint:* This is the same task as in the last exercise in Workshop 2. You can just use your solution here.\n",
    "\n",
    "3.  Merge the two data sets based on the columns `Title`, `FirstName` and `LastName` you just created using a _left join_ (_one-to-one_ merge).\n",
    "    Tabulate the columns and the number of non-missing observations to make sure that merging worked. \n",
    "\n",
    "    *Note:* The additional data set contains address information only for passengers from the UK, so some of these fields will be missing.\n",
    "\n",
    "4.  You are now in a position to merge the country of residence (_many-to-one_ merge). Load the country data from `UK_post_codes.csv` which contains \n",
    "    the UK post code prefix (which you can ignore), the corresponding city, and the corresponding country.\n",
    "\n",
    "    Merge this data with your passenger data set using a _left join_ (what is the correct merge key?).\n",
    "\n",
    "5.  Tabulate the number of observations by `Country`, including the number of observations with missing `Country` (these are passengers residing outside the UK).\n",
    "\n",
    "    Finally, compute the mean survival rate by country."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3-default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
